"""WorkflowOrchestrator class â€” orchestrates the full GitHub issue creation and status workflow."""

import logging
from typing import TYPE_CHECKING

from src.models.recommendation import IssueMetadata, IssueRecommendation
from src.models.workflow import (
    TriggeredBy,
    WorkflowConfiguration,
    WorkflowResult,
    WorkflowTransition,
)
from src.services.agent_tracking import append_tracking_to_body
from src.utils import utcnow

from .config import _transitions, get_workflow_config
from .models import (
    PipelineState,
    WorkflowContext,
    WorkflowState,
    _ci_get,
    find_next_actionable_status,
    get_agent_slugs,
    get_status_order,
)
from .transitions import (
    get_issue_main_branch,
    get_issue_sub_issues,
    get_pipeline_state,
    set_issue_main_branch,
    set_issue_sub_issues,
    set_pipeline_state,
)

if TYPE_CHECKING:
    from src.services.ai_agent import AIAgentService
    from src.services.github_projects import GitHubProjectsService

logger = logging.getLogger(__name__)


class WorkflowOrchestrator:
    """Orchestrates the full GitHub issue creation and status workflow."""

    def __init__(
        self,
        ai_service: "AIAgentService",
        github_service: "GitHubProjectsService",
    ):
        self.ai = ai_service
        self.github = github_service

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HELPER: Format Issue Body
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def format_issue_body(self, recommendation: IssueRecommendation) -> str:
        """
        Format recommendation into markdown body for GitHub Issue.

        Produces a comprehensive issue body that preserves all user details
        and includes technical guidance for the implementing agent.

        Args:
            recommendation: The AI-generated recommendation

        Returns:
            Formatted markdown string
        """
        requirements_list = "\n".join(f"- {req}" for req in recommendation.functional_requirements)

        # Original context section â€” preserves the user's verbatim input
        original_context = getattr(recommendation, "original_context", "") or ""
        original_context_section = ""
        if original_context and original_context != recommendation.original_input:
            original_context_section = f"""## Original Request

> {original_context.replace(chr(10), chr(10) + "> ")}

"""
        elif recommendation.original_input:
            original_context_section = f"""## Original Request

> {recommendation.original_input.replace(chr(10), chr(10) + "> ")}

"""

        # Technical notes section
        technical_notes = getattr(recommendation, "technical_notes", "") or ""
        technical_notes_section = ""
        if technical_notes:
            technical_notes_section = f"""## Technical Notes

{technical_notes}

"""

        # Format metadata section
        metadata = (
            recommendation.metadata
            if hasattr(recommendation, "metadata") and recommendation.metadata
            else None
        )
        metadata_section = ""
        if metadata:
            labels_str = ", ".join(f"`{lbl}`" for lbl in (metadata.labels or []))
            metadata_section = f"""## Metadata

| Field | Value |
|-------|-------|
| Priority | {metadata.priority.value if metadata.priority else "P2"} |
| Size | {metadata.size.value if metadata.size else "M"} |
| Estimate | {metadata.estimate_hours}h |
| Start Date | {metadata.start_date or "TBD"} |
| Target Date | {metadata.target_date or "TBD"} |
| Labels | {labels_str} |

"""

        body = f"""{original_context_section}## User Story

{recommendation.user_story}

## UI/UX Description

{recommendation.ui_ux_description}

## Functional Requirements

{requirements_list}

{technical_notes_section}{metadata_section}---
*Generated by AI from feature request*
"""
        return body

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HELPER: Update Agent Tracking in Issue Body
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def _update_agent_tracking_state(
        self,
        ctx: WorkflowContext,
        agent_name: str,
        new_state: str,
    ) -> bool:
        """
        Update the agent tracking table in the GitHub Issue body.

        Fetches the current issue body, updates the agent's state in the
        tracking table, and pushes the updated body back to GitHub.

        Args:
            ctx: Workflow context with issue info
            agent_name: Agent name (e.g. "speckit.specify")
            new_state: "active" or "done"

        Returns:
            True if the issue body was updated successfully
        """
        from src.services.agent_tracking import mark_agent_active, mark_agent_done

        if not ctx.issue_number:
            return False

        try:
            issue_data = await self.github.get_issue_with_comments(
                access_token=ctx.access_token,
                owner=ctx.repository_owner,
                repo=ctx.repository_name,
                issue_number=ctx.issue_number,
            )
            body = issue_data.get("body", "")
            if not body:
                return False

            if new_state == "active":
                updated_body = mark_agent_active(body, agent_name)
            elif new_state == "done":
                updated_body = mark_agent_done(body, agent_name)
            else:
                logger.warning("Unknown tracking state: %s", new_state)
                return False

            if updated_body == body:
                logger.debug("No tracking change for agent '%s' (state=%s)", agent_name, new_state)
                return True  # No change needed

            success = await self.github.update_issue_body(
                access_token=ctx.access_token,
                owner=ctx.repository_owner,
                repo=ctx.repository_name,
                issue_number=ctx.issue_number,
                body=updated_body,
            )
            if success:
                logger.info(
                    "Updated tracking: agent '%s' â†’ %s on issue #%d",
                    agent_name,
                    new_state,
                    ctx.issue_number,
                )
            return success
        except Exception as e:
            logger.warning("Failed to update agent tracking for issue #%d: %s", ctx.issue_number, e)
            return False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HELPER: Log Transition
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def log_transition(
        self,
        ctx: WorkflowContext,
        from_status: str | None,
        to_status: str,
        triggered_by: TriggeredBy,
        success: bool,
        error_message: str | None = None,
        assigned_user: str | None = None,
    ) -> WorkflowTransition:
        """
        Log a workflow transition for audit purposes.

        Args:
            ctx: Current workflow context
            from_status: Previous status
            to_status: New status
            triggered_by: What triggered the transition
            success: Whether it succeeded
            error_message: Error details if failed
            assigned_user: User assigned during transition

        Returns:
            The created transition record
        """
        transition = WorkflowTransition(
            issue_id=ctx.issue_id or "",
            project_id=ctx.project_id,
            from_status=from_status,
            to_status=to_status,
            assigned_user=assigned_user,
            triggered_by=triggered_by,
            success=success,
            error_message=error_message,
        )
        _transitions.append(transition)
        logger.info(
            "Transition logged: %s â†’ %s (success=%s)",
            from_status or "None",
            to_status,
            success,
        )
        return transition

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HELPER: Create All Sub-Issues Upfront
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def create_all_sub_issues(
        self,
        ctx: WorkflowContext,
    ) -> dict[str, dict]:
        """
        Create sub-issues for every agent in the pipeline, upfront.

        Iterates over all statuses in the workflow configuration and creates
        a sub-issue per agent so the user can see the full scope of work
        immediately after the main issue is created.

        Args:
            ctx: Workflow context with issue info populated

        Returns:
            Dict mapping agent_name â†’ {"number": int, "node_id": str, "url": str}
        """
        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config or not ctx.issue_number or not ctx.repository_owner:
            return {}

        # Fetch parent issue data once for body tailoring
        try:
            parent_issue_data = await self.github.get_issue_with_comments(
                access_token=ctx.access_token,
                owner=ctx.repository_owner,
                repo=ctx.repository_name,
                issue_number=ctx.issue_number,
            )
            parent_body = parent_issue_data.get("body", "")
            parent_title = parent_issue_data.get("title", f"Issue #{ctx.issue_number}")
        except Exception as e:
            logger.warning("Failed to fetch parent issue for sub-issue creation: %s", e)
            return {}

        # Collect all agents across all statuses in pipeline order
        all_agents: list[str] = []
        for status in get_status_order(config):
            slugs = get_agent_slugs(config, status)
            for slug in slugs:
                if slug not in all_agents:
                    all_agents.append(slug)

        if not all_agents:
            return {}

        logger.info(
            "Creating %d sub-issues upfront for issue #%d: %s",
            len(all_agents),
            ctx.issue_number,
            ", ".join(all_agents),
        )

        agent_sub_issues: dict[str, dict] = {}

        for agent_name in all_agents:
            try:
                sub_body = self.github.tailor_body_for_agent(
                    parent_body=parent_body,
                    agent_name=agent_name,
                    parent_issue_number=ctx.issue_number,
                    parent_title=parent_title,
                )

                sub_issue = await self.github.create_sub_issue(
                    access_token=ctx.access_token,
                    owner=ctx.repository_owner,
                    repo=ctx.repository_name,
                    parent_issue_number=ctx.issue_number,
                    title=f"[{agent_name}] {parent_title}",
                    body=sub_body,
                    labels=["ai-generated", "sub-issue"],
                )

                agent_sub_issues[agent_name] = {
                    "number": sub_issue.get("number"),
                    "node_id": sub_issue.get("node_id", ""),
                    "url": sub_issue.get("html_url", ""),
                }

                logger.info(
                    "Created sub-issue #%d for agent '%s' (parent #%d)",
                    sub_issue.get("number"),
                    agent_name,
                    ctx.issue_number,
                )

                # Add the sub-issue to the same GitHub Project as the parent
                sub_node_id = sub_issue.get("node_id", "")
                if sub_node_id and ctx.project_id:
                    try:
                        await self.github.add_issue_to_project(
                            access_token=ctx.access_token,
                            project_id=ctx.project_id,
                            issue_node_id=sub_node_id,
                        )
                        logger.info(
                            "Added sub-issue #%d to project %s",
                            sub_issue.get("number"),
                            ctx.project_id,
                        )
                    except Exception as proj_err:
                        logger.warning(
                            "Failed to add sub-issue #%d to project: %s",
                            sub_issue.get("number"),
                            proj_err,
                        )
            except Exception as e:
                logger.warning(
                    "Failed to create sub-issue for agent '%s' on issue #%d: %s",
                    agent_name,
                    ctx.issue_number,
                    e,
                )

        # Persist sub-issue mappings in the global store so they survive
        # pipeline state resets during status transitions.
        if agent_sub_issues and ctx.issue_number:
            set_issue_sub_issues(ctx.issue_number, agent_sub_issues)

        return agent_sub_issues

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 1: Create GitHub Issue (T022)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def create_issue_from_recommendation(
        self, ctx: WorkflowContext, recommendation: IssueRecommendation
    ) -> dict:
        """
        Create GitHub Issue from confirmed recommendation.

        Args:
            ctx: Workflow context with auth and project info
            recommendation: The confirmed recommendation

        Returns:
            Dict with issue details (id, node_id, number, html_url)

        Raises:
            Exception: If issue creation fails
        """
        logger.info("Creating GitHub issue: %s", recommendation.title)
        ctx.current_state = WorkflowState.CREATING

        body = self.format_issue_body(recommendation)

        # Append the agent pipeline tracking table to the issue body
        config = ctx.config or await get_workflow_config(ctx.project_id)
        if config and config.agent_mappings:
            status_order = get_status_order(config)
            body = append_tracking_to_body(body, config.agent_mappings, status_order)
            logger.info("Appended agent pipeline tracking to issue body")

        issue = await self.github.create_issue(
            access_token=ctx.access_token,
            owner=ctx.repository_owner,
            repo=ctx.repository_name,
            title=recommendation.title,
            body=body,
            labels=["ai-generated"],
        )

        ctx.issue_id = issue["node_id"]
        ctx.issue_number = issue["number"]
        ctx.issue_url = issue["html_url"]

        logger.info("Created issue #%d: %s", issue["number"], issue["html_url"])
        return issue

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 2: Add to Project with Backlog Status (T023)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def add_to_project_with_backlog(
        self, ctx: WorkflowContext, recommendation: IssueRecommendation | None = None
    ) -> str:
        """
        Add created issue to GitHub Project with Backlog status.

        Args:
            ctx: Workflow context with issue_id populated
            recommendation: Optional recommendation with metadata to set

        Returns:
            Project item ID

        Raises:
            Exception: If project attachment fails
        """
        if not ctx.issue_id:
            raise ValueError("No issue_id in context - create issue first")

        logger.info("Adding issue %s to project %s", ctx.issue_id, ctx.project_id)

        # Add issue to project
        item_id = await self.github.add_issue_to_project(
            access_token=ctx.access_token,
            project_id=ctx.project_id,
            issue_node_id=ctx.issue_id,
        )

        ctx.project_item_id = item_id
        ctx.current_state = WorkflowState.BACKLOG

        # Explicitly set the Backlog status on the project item
        config = ctx.config or await get_workflow_config(ctx.project_id)
        backlog_status = config.status_backlog if config else "Backlog"
        status_set = await self.github.update_item_status_by_name(
            access_token=ctx.access_token,
            project_id=ctx.project_id,
            item_id=item_id,
            status_name=backlog_status,
        )
        if status_set:
            logger.info("Set project item status to '%s'", backlog_status)
        else:
            logger.warning("Failed to set project item status to '%s'", backlog_status)

        # Set metadata fields if recommendation has metadata
        if recommendation and hasattr(recommendation, "metadata") and recommendation.metadata:
            await self._set_issue_metadata(ctx, recommendation.metadata)

        # Log the transition
        self.log_transition(
            ctx=ctx,
            from_status=None,
            to_status="Backlog",
            triggered_by=TriggeredBy.AUTOMATIC,
            success=True,
        )

        logger.info("Added to project, item_id: %s", item_id)
        return item_id

    async def _set_issue_metadata(self, ctx: WorkflowContext, metadata: "IssueMetadata") -> None:
        """
        Set metadata fields on a project item.

        Args:
            ctx: Workflow context with project_item_id populated
            metadata: IssueMetadata with priority, size, dates, etc.
        """
        if not ctx.project_item_id:
            logger.warning("No project_item_id - cannot set metadata")
            return

        try:
            # Convert metadata to dict for the service
            metadata_dict = {
                "priority": metadata.priority.value if metadata.priority else None,
                "size": metadata.size.value if metadata.size else None,
                "estimate_hours": metadata.estimate_hours,
                "start_date": metadata.start_date,
                "target_date": metadata.target_date,
            }

            results = await self.github.set_issue_metadata(
                access_token=ctx.access_token,
                project_id=ctx.project_id,
                item_id=ctx.project_item_id,
                metadata=metadata_dict,
            )

            logger.info("Metadata set results: %s", results)

        except Exception as e:
            # Log but don't fail the workflow - metadata is nice-to-have
            logger.warning("Failed to set issue metadata: %s", e)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 3: Transition to Ready (T031)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def transition_to_ready(self, ctx: WorkflowContext) -> bool:
        """
        Automatically transition issue from Backlog to Ready.

        Args:
            ctx: Workflow context with project_item_id populated

        Returns:
            True if transition succeeded
        """
        if not ctx.project_item_id:
            raise ValueError("No project_item_id in context - add to project first")

        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config:
            logger.warning("No workflow config for project %s", ctx.project_id)
            return False

        logger.info("Transitioning issue %s to Ready", ctx.issue_id)

        # Get status field info from project
        # This will be implemented in github_projects.py
        success = await self.github.update_item_status_by_name(
            access_token=ctx.access_token,
            project_id=ctx.project_id,
            item_id=ctx.project_item_id,
            status_name=config.status_ready,
        )

        if success:
            ctx.current_state = WorkflowState.READY
            self.log_transition(
                ctx=ctx,
                from_status=config.status_backlog,
                to_status=config.status_ready,
                triggered_by=TriggeredBy.AUTOMATIC,
                success=True,
            )
        else:
            self.log_transition(
                ctx=ctx,
                from_status=config.status_backlog,
                to_status=config.status_ready,
                triggered_by=TriggeredBy.AUTOMATIC,
                success=False,
                error_message="Failed to update status",
            )

        return success

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # HELPER: Assign Agent for Status
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def assign_agent_for_status(
        self,
        ctx: WorkflowContext,
        status: str,
        agent_index: int = 0,
    ) -> bool:
        """
        Look up agent_mappings for the given status and assign the agent
        at the specified index to the issue.

        Creates or updates a PipelineState to track progress.

        Args:
            ctx: Workflow context with issue info
            status: Workflow status name (e.g., "Backlog", "Ready")
            agent_index: Index into the agent list for this status (default: 0 = first agent)

        Returns:
            True if agent assignment succeeded
        """
        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config:
            logger.warning("No workflow config for project %s", ctx.project_id)
            return False

        if ctx.issue_id is None:
            raise ValueError("issue_id required for agent assignment")
        if ctx.issue_number is None:
            raise ValueError("issue_number required for agent assignment")

        agents = _ci_get(config.agent_mappings, status, [])
        if not agents:
            logger.info("No agents configured for status '%s'", status)
            return True  # No agents to assign is not an error

        if agent_index >= len(agents):
            logger.info(
                "Agent index %d out of range for status '%s' (has %d agents)",
                agent_index,
                status,
                len(agents),
            )
            return True  # All agents already processed

        agent_name = (
            agents[agent_index].slug
            if hasattr(agents[agent_index], "slug")
            else str(agents[agent_index])
        )
        logger.info(
            "Assigning agent '%s' (index %d/%d) for status '%s' on issue #%s",
            agent_name,
            agent_index + 1,
            len(agents),
            status,
            ctx.issue_number,
        )

        # Determine the base branch for this agent
        #
        # Branching strategy (hierarchical PR model):
        #   - The FIRST agent uses base_ref="main":
        #       Creates branch "copilot/xxx" â†’ PR targets "main"
        #       This PR's branch becomes the "main branch" for the issue.
        #   - ALL subsequent agents use the HEAD commit SHA of the main branch:
        #       base_ref=<commit_sha> â†’ Copilot creates a CHILD branch from that commit
        #       The child PR targets the main branch (not "main")
        #       After the agent completes, the child PR is squash-merged into the
        #       main branch and the child branch is deleted.
        #
        # We pass the main PR's **branch name** (not a commit SHA) as baseRef
        # because GitHub's Copilot assignment API requires a valid ref name.
        # Copilot will create a new child branch from the HEAD of that branch
        # and open a PR targeting it.
        existing_pr = None
        base_ref = "main"
        current_head_sha = ""  # Track HEAD SHA at assignment time

        if ctx.issue_number:
            # Check if we already have a "main branch" stored for this issue
            main_branch_info = get_issue_main_branch(ctx.issue_number)

            if main_branch_info:
                # Subsequent agent â€” create a child branch from the main branch.
                main_branch = str(main_branch_info["branch"])
                main_pr_number = main_branch_info["pr_number"]

                # Fetch current PR details to capture the latest HEAD SHA
                # (used for tracking/audit purposes, NOT as baseRef)
                pr_details = await self.github.get_pull_request(
                    access_token=ctx.access_token,
                    owner=ctx.repository_owner,
                    repo=ctx.repository_name,
                    pr_number=main_pr_number,
                )

                if pr_details and pr_details.get("last_commit", {}).get("sha"):
                    current_head_sha = pr_details["last_commit"]["sha"]
                    logger.info(
                        "Captured HEAD SHA '%s' for agent '%s' on issue #%d",
                        current_head_sha[:8],
                        agent_name,
                        ctx.issue_number,
                    )

                # Use the main PR's branch name as base_ref so Copilot creates
                # a child branch from it. The child PR will target this branch.
                base_ref = main_branch

                logger.info(
                    "Agent '%s' will create child branch from '%s' (main branch '%s', PR #%d) "
                    "for issue #%d",
                    agent_name,
                    base_ref[:12] if len(base_ref) > 12 else base_ref,
                    main_branch,
                    main_pr_number,
                    ctx.issue_number,
                )

                # Pass existing_pr as informational context only â€” subsequent
                # agents create their own child PRs but benefit from knowing
                # about the main PR for context.
                existing_pr = {
                    "number": main_pr_number,
                    "head_ref": main_branch,
                }
            else:
                # First agent â€” check for existing PR to establish main branch
                try:
                    existing_pr = await self.github.find_existing_pr_for_issue(
                        access_token=ctx.access_token,
                        owner=ctx.repository_owner,
                        repo=ctx.repository_name,
                        issue_number=ctx.issue_number,
                    )
                    if existing_pr:
                        # Fetch full PR details to get commit SHA
                        pr_details = await self.github.get_pull_request(
                            access_token=ctx.access_token,
                            owner=ctx.repository_owner,
                            repo=ctx.repository_name,
                            pr_number=existing_pr["number"],
                        )
                        head_sha = ""
                        if pr_details and pr_details.get("last_commit", {}).get("sha"):
                            head_sha = pr_details["last_commit"]["sha"]

                        # Store this as the main branch for the issue
                        set_issue_main_branch(
                            ctx.issue_number,
                            existing_pr["head_ref"],
                            existing_pr["number"],
                            head_sha,
                        )
                        logger.info(
                            "Established main branch for issue #%s: '%s' (PR #%d, SHA: %s)",
                            ctx.issue_number,
                            existing_pr["head_ref"],
                            existing_pr["number"],
                            head_sha[:8] if head_sha else "none",
                        )

                        # An existing PR means a previous agent already
                        # created the issue's "working branch".  ALL
                        # subsequent agents â€” regardless of agent_index
                        # within the current status â€” must branch FROM
                        # this working branch, not from "main".
                        #
                        # agent_index is relative to the current status
                        # (e.g. 0 for speckit.plan in Ready) but the
                        # pipeline may be well past the first overall
                        # agent.  Using the discovered branch ensures
                        # every agent builds on previous work.
                        base_ref = str(existing_pr["head_ref"])
                        current_head_sha = head_sha
                        logger.info(
                            "Using discovered branch '%s' as base_ref "
                            "for agent '%s' (index %d) on issue #%s "
                            "(existing PR #%d)",
                            base_ref,
                            agent_name,
                            agent_index,
                            ctx.issue_number,
                            existing_pr["number"],
                        )

                        # Link the first PR to the GitHub Issue
                        try:
                            await self.github.link_pull_request_to_issue(
                                access_token=ctx.access_token,
                                owner=ctx.repository_owner,
                                repo=ctx.repository_name,
                                pr_number=existing_pr["number"],
                                issue_number=ctx.issue_number,
                            )
                        except Exception as e:
                            logger.warning(
                                "Failed to link PR #%d to issue #%d: %s",
                                existing_pr["number"],
                                ctx.issue_number,
                                e,
                            )
                except Exception as e:
                    logger.warning("Failed to check for existing PR: %s", e)

        # â”€â”€ Look up pre-created Sub-Issue for this agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Sub-issues are created upfront in create_all_sub_issues() so
        # the user can see the full scope immediately.  Here we look up
        # the existing sub-issue from the pipeline state, falling back to
        # the global sub-issue store which survives pipeline state resets.
        sub_issue_node_id = ctx.issue_id  # fallback: parent issue
        sub_issue_number = ctx.issue_number  # fallback: parent issue number
        sub_issue_info: dict | None = None

        existing_pipeline = get_pipeline_state(ctx.issue_number)
        if existing_pipeline and existing_pipeline.agent_sub_issues:
            pre_created = existing_pipeline.agent_sub_issues.get(agent_name)
            if pre_created:
                sub_issue_node_id = pre_created.get("node_id", ctx.issue_id)
                sub_issue_number = pre_created.get("number", ctx.issue_number)
                sub_issue_info = pre_created
                logger.info(
                    "Using pre-created sub-issue #%d for agent '%s' (parent #%d)",
                    sub_issue_number,
                    agent_name,
                    ctx.issue_number,
                )

        # Fall back to the global sub-issue store (survives pipeline resets)
        if sub_issue_info is None:
            global_subs = get_issue_sub_issues(ctx.issue_number)
            pre_created = global_subs.get(agent_name)
            if pre_created:
                sub_issue_node_id = pre_created.get("node_id", ctx.issue_id)
                sub_issue_number = pre_created.get("number", ctx.issue_number)
                sub_issue_info = pre_created
                logger.info(
                    "Using sub-issue #%d from global store for agent '%s' (parent #%d)",
                    sub_issue_number,
                    agent_name,
                    ctx.issue_number,
                )

        if sub_issue_info is None:
            logger.warning(
                "No pre-created sub-issue found for agent '%s' on issue #%d â€” "
                "falling back to parent issue",
                agent_name,
                ctx.issue_number,
            )

        # Fetch issue context for the agent's custom instructions.
        # Use the SUB-ISSUE data (not parent) so Copilot focuses only on
        # the sub-issue and doesn't create duplicate PRs for the parent.
        custom_instructions = ""
        instruction_issue_number = sub_issue_number if sub_issue_info else ctx.issue_number
        if instruction_issue_number:
            try:
                issue_data = await self.github.get_issue_with_comments(
                    access_token=ctx.access_token,
                    owner=ctx.repository_owner,
                    repo=ctx.repository_name,
                    issue_number=instruction_issue_number,
                )
                custom_instructions = self.github.format_issue_context_as_prompt(
                    issue_data,
                    agent_name=agent_name,
                    existing_pr=existing_pr,
                )
                logger.info(
                    "Prepared custom instructions for agent '%s' from issue #%d (length: %d chars, existing_pr: %s)",
                    agent_name,
                    instruction_issue_number,
                    len(custom_instructions),
                    f"#{existing_pr['number']}" if existing_pr else "None",
                )
            except Exception as e:
                logger.warning("Failed to fetch issue context for agent '%s': %s", agent_name, e)

        # Assign the agent with retry-with-backoff
        # GitHub's Copilot API can return transient errors, especially right after
        # a child PR merge. We retry up to 3 times with exponential backoff.
        import asyncio

        # â”€â”€ Dedup guard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # If this exact agent+issue was already assigned recently (within
        # the grace period), skip the duplicate assignment.  This closes
        # race windows where multiple code-paths (polling steps, recovery,
        # status-transition) all converge on the same assignment.
        pending_key = f"{ctx.issue_number}:{agent_name}"
        try:
            from src.services.copilot_polling import (
                ASSIGNMENT_GRACE_PERIOD_SECONDS,
                _pending_agent_assignments,
                _recovery_last_attempt,
            )

            existing_ts = _pending_agent_assignments.get(pending_key)
            if existing_ts is not None:
                age = (utcnow() - existing_ts).total_seconds()
                if age < ASSIGNMENT_GRACE_PERIOD_SECONDS:
                    logger.warning(
                        "Skipping duplicate assignment of agent '%s' on issue #%d "
                        "(already assigned %.0fs ago, grace=%ds)",
                        agent_name,
                        ctx.issue_number,
                        age,
                        ASSIGNMENT_GRACE_PERIOD_SECONDS,
                    )
                    return True  # Treat as success â€” the original assignment is in flight

            # Pre-set recovery cooldown and pending flag BEFORE the assignment
            # API call. This prevents a race where the polling/recovery loop sees
            # the issue between the unassign and re-assign steps and fires a
            # duplicate assignment.
            _recovery_last_attempt[ctx.issue_number] = utcnow()
            _pending_agent_assignments[pending_key] = utcnow()
            logger.debug(
                "Pre-set recovery cooldown and pending flag for agent '%s' on issue #%d",
                agent_name,
                ctx.issue_number,
            )
        except ImportError:
            pass  # copilot_polling not available in tests

        max_retries = 3
        base_delay = 3  # seconds
        success = False

        for attempt in range(max_retries):
            logger.info(
                "Assigning agent '%s' to sub-issue #%s (parent #%s) with base_ref='%s' (attempt %d/%d)",
                agent_name,
                sub_issue_number,
                ctx.issue_number,
                base_ref,
                attempt + 1,
                max_retries,
            )
            success = await self.github.assign_copilot_to_issue(
                access_token=ctx.access_token,
                owner=ctx.repository_owner,
                repo=ctx.repository_name,
                issue_node_id=sub_issue_node_id,
                issue_number=sub_issue_number,
                base_ref=base_ref,
                custom_agent=agent_name,
                custom_instructions=custom_instructions,
            )

            if success:
                break

            if attempt < max_retries - 1:
                delay = base_delay * (2**attempt)  # 3s, 6s, 12s
                logger.warning(
                    "Agent assignment failed for '%s' on issue #%s, retrying in %ds...",
                    agent_name,
                    ctx.issue_number,
                    delay,
                )
                await asyncio.sleep(delay)

        if success:
            logger.info(
                "Successfully assigned agent '%s' to issue #%s (base_ref='%s')",
                agent_name,
                ctx.issue_number,
                base_ref,
            )

            # Mark agent as ðŸ”„ Active in the issue body tracking table
            await self._update_agent_tracking_state(ctx, agent_name, "active")

            # Mark the sub-issue as "in progress" (add label, ensure open)
            if sub_issue_info and sub_issue_number != ctx.issue_number:
                try:
                    await self.github.update_issue_state(
                        access_token=ctx.access_token,
                        owner=ctx.repository_owner,
                        repo=ctx.repository_name,
                        issue_number=sub_issue_number,
                        state="open",
                        labels_add=["in-progress"],
                    )
                    logger.info(
                        "Marked sub-issue #%d as in-progress for agent '%s'",
                        sub_issue_number,
                        agent_name,
                    )
                except Exception as e:
                    logger.warning(
                        "Failed to mark sub-issue #%d as in-progress: %s",
                        sub_issue_number,
                        e,
                    )

                # Update the sub-issue's project board Status to "In Progress"
                try:
                    sub_node_id = sub_issue_info.get("node_id", "")
                    if sub_node_id:
                        await self.github.update_sub_issue_project_status(
                            access_token=ctx.access_token,
                            project_id=ctx.project_id,
                            sub_issue_node_id=sub_node_id,
                            status_name=(config.status_in_progress if config else "In Progress"),
                        )
                except Exception as e:
                    logger.warning(
                        "Failed to update sub-issue #%d project board status: %s",
                        sub_issue_number,
                        e,
                    )

            # Refresh recovery cooldown timestamp now that assignment succeeded
            try:
                from src.services.copilot_polling import (
                    _recovery_last_attempt,
                )

                _recovery_last_attempt[ctx.issue_number] = utcnow()
            except ImportError:
                pass
        else:
            logger.warning(
                "Failed to assign agent '%s' to issue #%s",
                agent_name,
                ctx.issue_number,
            )
            # Clear pending flag so recovery can retry later
            try:
                from src.services.copilot_polling import (
                    _pending_agent_assignments,
                )

                _pending_agent_assignments.pop(pending_key, None)
            except ImportError:
                pass

        # Create / update pipeline state
        # Capture the HEAD SHA at assignment time for commit-based completion detection
        assigned_sha = current_head_sha or ""
        if not assigned_sha and ctx.issue_number:
            main_branch_info = get_issue_main_branch(ctx.issue_number)
            if main_branch_info and main_branch_info.get("head_sha"):
                assigned_sha = main_branch_info.get("head_sha", "")

        # Preserve existing sub-issue mappings from previous agents
        existing_pipeline = get_pipeline_state(ctx.issue_number)
        existing_sub_issues = existing_pipeline.agent_sub_issues if existing_pipeline else {}

        # Add the new agent's sub-issue info
        agent_sub_issues = dict(existing_sub_issues)
        if sub_issue_info:
            agent_sub_issues[agent_name] = sub_issue_info

        pipeline_state = PipelineState(
            issue_number=ctx.issue_number,
            project_id=ctx.project_id,
            status=status,
            agents=[a.slug if hasattr(a, "slug") else str(a) for a in agents],
            current_agent_index=agent_index,
            completed_agents=[
                a.slug if hasattr(a, "slug") else str(a) for a in agents[:agent_index]
            ],
            started_at=utcnow(),
            error=None if success else f"Failed to assign agent '{agent_name}'",
            agent_assigned_sha=assigned_sha,
            agent_sub_issues=agent_sub_issues,
        )
        set_pipeline_state(ctx.issue_number, pipeline_state)

        # Log the transition
        self.log_transition(
            ctx=ctx,
            from_status=status,
            to_status=status,
            triggered_by=TriggeredBy.AUTOMATIC,
            success=success,
            assigned_user=f"copilot:{agent_name}" if success else None,
            error_message=None if success else f"Failed to assign agent '{agent_name}'",
        )

        return success

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 4: Handle Ready Status (T038, T042)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def handle_ready_status(self, ctx: WorkflowContext) -> bool:
        """
        When Ready status detected: assign first In Progress agent and transition.

        Delegates to ``assign_agent_for_status`` so there is a single code path
        for PR detection, instruction formatting, and Copilot assignment.

        Args:
            ctx: Workflow context

        Returns:
            True if transition succeeded (assignment failures are logged but don't fail the transition)
        """
        if ctx.issue_number is None:
            raise ValueError("issue_number required for handle_ready_to_in_progress")
        if ctx.project_item_id is None:
            raise ValueError("project_item_id required for handle_ready_to_in_progress")

        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config:
            logger.warning("No workflow config for project %s", ctx.project_id)
            return False

        logger.info(
            "Issue %s is Ready, assigning agent and transitioning to In Progress",
            ctx.issue_id,
        )

        # Get agent slugs for In Progress status from agent_mappings
        in_progress_slugs = get_agent_slugs(config, config.status_in_progress)

        # Assign the first In Progress agent (reuses PR detection + instruction logic)
        copilot_assigned = await self.assign_agent_for_status(
            ctx, config.status_in_progress, agent_index=0
        )

        if not copilot_assigned:
            logger.warning(
                "Could not assign agent to issue #%d - attempting fallback",
                ctx.issue_number,
            )
            # Fall back to configured assignee if Copilot assignment failed
            assignee = config.copilot_assignee
            if assignee:
                assignee_valid = await self.github.validate_assignee(
                    access_token=ctx.access_token,
                    owner=ctx.repository_owner,
                    repo=ctx.repository_name,
                    username=assignee,
                )

                if assignee_valid:
                    assign_success = await self.github.assign_issue(
                        access_token=ctx.access_token,
                        owner=ctx.repository_owner,
                        repo=ctx.repository_name,
                        issue_number=ctx.issue_number,
                        assignees=[assignee],
                    )
                    if assign_success:
                        logger.info(
                            "Fallback: Assigned %s to issue #%d",
                            assignee,
                            ctx.issue_number,
                        )
                    else:
                        logger.warning(
                            "Fallback: Failed to assign %s to issue #%d",
                            assignee,
                            ctx.issue_number,
                        )

        # Update status to In Progress
        status_success = await self.github.update_item_status_by_name(
            access_token=ctx.access_token,
            project_id=ctx.project_id,
            item_id=ctx.project_item_id,
            status_name=config.status_in_progress,
        )

        if not status_success:
            self.log_transition(
                ctx=ctx,
                from_status=config.status_ready,
                to_status=config.status_in_progress,
                triggered_by=TriggeredBy.AUTOMATIC,
                success=False,
                error_message="Failed to update status to In Progress",
            )
            return False

        ctx.current_state = WorkflowState.IN_PROGRESS

        # Log which agent was used
        agent_name = in_progress_slugs[0] if in_progress_slugs else ""
        self.log_transition(
            ctx=ctx,
            from_status=config.status_ready,
            to_status=config.status_in_progress,
            triggered_by=TriggeredBy.AUTOMATIC,
            success=True,
            assigned_user=(
                f"copilot:{agent_name}"
                if agent_name and copilot_assigned
                else ("copilot" if copilot_assigned else config.copilot_assignee)
            ),
        )

        return True

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 5: Handle In Progress Status - Check for PR Completion
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def handle_in_progress_status(self, ctx: WorkflowContext) -> bool:
        """
        When issue is In Progress: check if Copilot has completed the PR.

        If Copilot has finished (PR is no longer draft), this will:
        1. Update issue status to In Review
        2. Mark the draft PR as ready for review (if still draft)
        3. Assign reviewer to the issue

        Args:
            ctx: Workflow context

        Returns:
            True if PR completion detected and handled, False if still in progress
        """
        if ctx.issue_number is None:
            raise ValueError("issue_number required for handle_in_progress")
        if ctx.project_item_id is None:
            raise ValueError("project_item_id required for handle_in_progress")

        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config:
            logger.warning("No workflow config for project %s", ctx.project_id)
            return False

        logger.info("Checking if Copilot has completed PR for issue #%d", ctx.issue_number)

        # Check for completed Copilot PR
        completed_pr = await self.github.check_copilot_pr_completion(
            access_token=ctx.access_token,
            owner=ctx.repository_owner,
            repo=ctx.repository_name,
            issue_number=ctx.issue_number,
        )

        if not completed_pr:
            logger.info(
                "No completed Copilot PR found for issue #%d - still in progress",
                ctx.issue_number,
            )
            return False

        logger.info(
            "Copilot PR #%d is complete for issue #%d, transitioning to In Review",
            completed_pr["number"],
            ctx.issue_number,
        )

        # If PR is still marked as draft, mark it ready for review
        if completed_pr.get("is_draft"):
            pr_node_id = completed_pr.get("id")
            if pr_node_id:
                mark_success = await self.github.mark_pr_ready_for_review(
                    access_token=ctx.access_token,
                    pr_node_id=pr_node_id,
                )
                if mark_success:
                    logger.info("Marked PR #%d as ready for review", completed_pr["number"])
                else:
                    logger.warning(
                        "Failed to mark PR #%d as ready for review",
                        completed_pr["number"],
                    )

        # Update status to In Review, assign reviewer
        success, reviewer = await self._transition_to_in_review(ctx, config)
        if not success:
            return False

        if reviewer:
            logger.info(
                "Issue #%d transitioned to In Review, assigned to %s, PR #%d ready",
                ctx.issue_number,
                reviewer,
                completed_pr["number"],
            )
        else:
            logger.warning(
                "Issue #%d transitioned to In Review but failed to assign reviewer",
                ctx.issue_number,
            )

        return True

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Shared: transition to In Review + assign reviewer
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def _transition_to_in_review(
        self,
        ctx: WorkflowContext,
        config: WorkflowConfiguration,
    ) -> tuple[bool, str | None]:
        """Update project status to In Review and assign a reviewer.

        Returns:
            ``(success, reviewer)``  where *reviewer* is the assigned login
            (or ``None`` if assignment failed / no reviewer resolved).
        """
        if ctx.project_item_id is None:
            logger.error("Cannot transition to In Review: project_item_id is None")
            return False, None

        status_success = await self.github.update_item_status_by_name(
            access_token=ctx.access_token,
            project_id=ctx.project_id,
            item_id=ctx.project_item_id,
            status_name=config.status_in_review,
        )

        if not status_success:
            self.log_transition(
                ctx=ctx,
                from_status=config.status_in_progress,
                to_status=config.status_in_review,
                triggered_by=TriggeredBy.DETECTION,
                success=False,
                error_message="Failed to update status to In Review",
            )
            return False, None

        # Determine reviewer (use configured or fall back to repo owner)
        reviewer = config.review_assignee
        if not reviewer:
            reviewer = await self.github.get_repository_owner(
                access_token=ctx.access_token,
                owner=ctx.repository_owner,
                repo=ctx.repository_name,
            )

        # Assign reviewer
        if ctx.issue_number is None:
            logger.error("Cannot assign reviewer: issue_number is None")
            return False, None

        assign_success = await self.github.assign_issue(
            access_token=ctx.access_token,
            owner=ctx.repository_owner,
            repo=ctx.repository_name,
            issue_number=ctx.issue_number,
            assignees=[reviewer] if reviewer else [],
        )

        ctx.current_state = WorkflowState.IN_REVIEW
        self.log_transition(
            ctx=ctx,
            from_status=config.status_in_progress,
            to_status=config.status_in_review,
            triggered_by=TriggeredBy.DETECTION,
            success=True,
            assigned_user=reviewer if assign_success else None,
        )

        if not assign_success:
            logger.warning(
                "Failed to assign reviewer %s to issue #%d",
                reviewer,
                ctx.issue_number,
            )

        return True, reviewer if assign_success else None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 6: Detect Completion Signal (T044)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def detect_completion_signal(self, task: dict) -> bool:
        """
        Check if a task has completion indicators.

        Completion is signaled when:
        - Issue is closed, OR
        - Issue has 'copilot-complete' label

        Args:
            task: Task/issue data from GitHub

        Returns:
            True if completion signal detected
        """
        # Check for closed status
        if task.get("state") == "closed":
            return True

        # Check for completion label
        labels = task.get("labels", [])
        label_names = [lbl.get("name", "") for lbl in labels]
        if "copilot-complete" in label_names:
            return True

        return False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # STEP 6: Handle Completion (T045)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def handle_completion(self, ctx: WorkflowContext) -> bool:
        """
        When completion detected: transition to In Review and assign owner.

        Args:
            ctx: Workflow context

        Returns:
            True if transition and assignment succeeded
        """
        if ctx.issue_number is None:
            raise ValueError("issue_number required for handle_completion")
        if ctx.project_item_id is None:
            raise ValueError("project_item_id required for handle_completion")

        config = ctx.config or await get_workflow_config(ctx.project_id)
        if not config:
            logger.warning("No workflow config for project %s", ctx.project_id)
            return False

        logger.info("Issue %s complete, transitioning to In Review", ctx.issue_id)

        success, reviewer = await self._transition_to_in_review(ctx, config)
        if not success:
            return False

        if not reviewer:
            logger.warning(
                "Failed to assign reviewer to issue #%d",
                ctx.issue_number,
            )

        return True

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # FULL WORKFLOW: Execute from confirmation to Ready (T022+T023+T031)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    async def execute_full_workflow(
        self, ctx: WorkflowContext, recommendation: IssueRecommendation
    ) -> WorkflowResult:
        """
        Execute the workflow from confirmation to Backlog status with first agent assigned.

        This orchestrates:
        1. Create GitHub Issue from recommendation
        2. Add issue to project with Backlog status
        3. Assign the first Backlog agent (e.g., speckit.specify)

        Subsequent transitions (Backlogâ†’Readyâ†’In Progress) are handled by the polling
        service as agents complete their work.

        Args:
            ctx: Workflow context
            recommendation: The confirmed recommendation

        Returns:
            WorkflowResult with success status and details
        """
        try:
            # Step 1: Create issue
            await self.create_issue_from_recommendation(ctx, recommendation)

            # Step 2: Add to project with metadata
            await self.add_to_project_with_backlog(ctx, recommendation)

            # Step 3: Assign the first agent for Backlog status
            # If Backlog has no agents, use pass-through to find next actionable status (T028)
            config = ctx.config or await get_workflow_config(ctx.project_id)
            status_name = config.status_backlog if config else "Backlog"

            if config and not get_agent_slugs(config, status_name):
                # Pass-through: advance to next status with agents
                next_status = find_next_actionable_status(config, status_name)
                if next_status:
                    logger.info(
                        "Pass-through: Backlog has no agents, advancing to '%s' for issue #%s",
                        next_status,
                        ctx.issue_number,
                    )
                    # Update project status
                    if ctx.project_item_id:
                        await self.github.update_item_status_by_name(
                            access_token=ctx.access_token,
                            project_id=ctx.project_id,
                            item_id=ctx.project_item_id,
                            status_name=next_status,
                        )
                    status_name = next_status

            # Pre-register the recovery cooldown BEFORE calling assign_agent_for_status.
            # This prevents the polling/recovery loop from racing during sub-issue
            # creation. NOTE: We only set _recovery_last_attempt (NOT
            # _pending_agent_assignments) because the latter would cause the dedup
            # guard inside assign_agent_for_status to skip the actual assignment.
            if ctx.issue_number:
                try:
                    from src.services.copilot_polling import (
                        _recovery_last_attempt,
                    )

                    _recovery_last_attempt[ctx.issue_number] = utcnow()
                    logger.debug(
                        "Set recovery cooldown for issue #%d before sub-issue creation",
                        ctx.issue_number,
                    )
                except ImportError:
                    pass

            # Create all sub-issues upfront so the user can see the full pipeline
            agent_sub_issues = await self.create_all_sub_issues(ctx)
            if agent_sub_issues and ctx.issue_number is not None:
                # Store in pipeline state so assign_agent_for_status can look them up
                pipeline_state = PipelineState(
                    issue_number=ctx.issue_number,
                    project_id=ctx.project_id,
                    status=status_name,
                    agents=[],  # Will be set properly by assign_agent_for_status
                    agent_sub_issues=agent_sub_issues,
                )
                set_pipeline_state(ctx.issue_number, pipeline_state)
                logger.info(
                    "Pre-created %d sub-issues for issue #%d",
                    len(agent_sub_issues),
                    ctx.issue_number,
                )

            await self.assign_agent_for_status(ctx, status_name, agent_index=0)

            # Check if agent assignment actually succeeded
            pipeline = get_pipeline_state(ctx.issue_number) if ctx.issue_number else None
            agent_error = pipeline.error if pipeline else None

            if agent_error:
                logger.warning(
                    "Issue #%d created but agent assignment had errors: %s",
                    ctx.issue_number,
                    agent_error,
                )
                return WorkflowResult(
                    success=False,
                    issue_id=ctx.issue_id,
                    issue_number=ctx.issue_number,
                    issue_url=ctx.issue_url,
                    project_item_id=ctx.project_item_id,
                    current_status=status_name,
                    message=(
                        f"Issue #{ctx.issue_number} created and added to project, "
                        f"but agent assignment failed: {agent_error}. "
                        f"The system will retry automatically, or you can retry manually."
                    ),
                )

            return WorkflowResult(
                success=True,
                issue_id=ctx.issue_id,
                issue_number=ctx.issue_number,
                issue_url=ctx.issue_url,
                project_item_id=ctx.project_item_id,
                current_status=status_name,
                message=(
                    f"Issue #{ctx.issue_number} created, added to project ({status_name}), "
                    f"and assigned to first agent"
                ),
            )

        except Exception as e:
            logger.error("Workflow failed: %s", e)
            ctx.current_state = WorkflowState.ERROR

            self.log_transition(
                ctx=ctx,
                from_status=ctx.current_state.value if ctx.current_state else None,
                to_status="error",
                triggered_by=TriggeredBy.AUTOMATIC,
                success=False,
                error_message=str(e),
            )

            return WorkflowResult(
                success=False,
                issue_id=ctx.issue_id,
                issue_number=ctx.issue_number,
                issue_url=ctx.issue_url,
                project_item_id=ctx.project_item_id,
                current_status="error",
                message=f"Workflow failed: {e}",
            )


# Global orchestrator instance (lazy initialization)
_orchestrator_instance: WorkflowOrchestrator | None = None


def get_workflow_orchestrator() -> WorkflowOrchestrator:
    """Get or create the global workflow orchestrator instance."""
    global _orchestrator_instance
    if _orchestrator_instance is None:
        from src.services.ai_agent import get_ai_agent_service
        from src.services.github_projects import github_projects_service

        _orchestrator_instance = WorkflowOrchestrator(
            ai_service=get_ai_agent_service(),
            github_service=github_projects_service,
        )
    return _orchestrator_instance
